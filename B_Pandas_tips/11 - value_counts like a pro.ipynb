{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas tip #11: value_counts like a pro\n",
    "One of my most common methods is .value_counts(). It combines a groupby() and count() and applies it on the same column. This gives me a quick idea on what values are present in the column.\n",
    "\n",
    "Only using .value_counts() is already great but it has much more to offer. For example, it has a build in normalizer to give a quick ratio on how offen values appear with respect to others. To normalize, just add normalize=True as a parameter.\n",
    "\n",
    "For a column containing a price, value counts might seem useless but it has another trick up its sleave: binning. In a previous post I already showed how to create histograms (and PDFs) and .value_counts() is yet another quick way to have a peek at the distribution. Simply add the amount of bins, e.g. bins=10, as a parameter. The .value_counts() is a column operation, therefore, it is quite limited compared to my previously discussed histogram methods.\n",
    "\n",
    "I really love this nifty shorthand methods which I previously calculated with a bit more code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate some random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_samples = 7_000\n",
    "region = ['Europe', 'America', 'Asia', 'Africa', 'Asia']\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "df = pd.DataFrame({\n",
    "    'order_id': np.arange(n_samples),\n",
    "    'price': np.round(\n",
    "        rng.normal(loc=500, scale=100, size=n_samples), \n",
    "        decimals=2,\n",
    "    ),\n",
    "    'region': rng.choice(region, size=n_samples)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".value_counts() is like a .groupby() with .count() on a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.region.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily normalize the data, i.e. divide by the len() of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick peek at the distribution we can create a histogram by binning the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.value_counts(normalize=True, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['price']\n",
    "    .value_counts(normalize=True, bins=10)\n",
    "    .sort_index()\n",
    "    .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any questions, comments, or requests, feel free to [contact me on LinkedIn](https://linkedin.com/in/dennisbakhuis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
